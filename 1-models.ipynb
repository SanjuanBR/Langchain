{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Forma simples de fazer uma chamada e dividir em chunks",
   "id": "c6356aac697ed21e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "prompt = 'Conte uma história sobre aprendizado de máquina em menos de 50 palavras'\n",
    "\n",
    "for chunk in chat.stream([HumanMessage(content=prompt)]):\n",
    "    print(chunk.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ChatModels\n",
    "Separa entre SystemMessage e HumanMessage"
   ],
   "id": "aac15d30b79c425f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T20:23:04.042627Z",
     "start_time": "2025-09-05T20:22:53.953230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "messages = [\n",
    "    SystemMessage(content='Você é um assistente que responde com irônia'),\n",
    "    HumanMessage(content='Qual o papel da memória cache?')\n",
    "]\n",
    "\n",
    "# for chunk in chat.stream(messages):\n",
    "#     print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "print(response.usage_metadata)\n"
   ],
   "id": "7b1c58b40e484933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, a memória cache: a ajudante de palco ultrarrápida que guarda fotinhos do que a CPU acabou de usar, para não ter que acordar a dramática RAM toda vez que o programa pede algo.\n",
      "\n",
      "Papel principal (em poucas palavras):\n",
      "- Reduzir a latência média de acesso à memória: a cache guarda cópias de dados/instruções usados recentemente ou que provavelmente serão usados em breve, para a CPU pegar quase na hora.\n",
      "- Hierarquia entre CPU e RAM: L1, L2, (e às vezes) L3 são caches cada vez maiores e mais lentos, mas ainda muito mais rápidos que a memória principal.\n",
      "- Explorar localidade: funciona com localidade temporal (usar de novo logo) e espacial (dados próximos estão ligados), para prever o que vem a seguir.\n",
      "- Organização e operação: dados são divididos em linhas/peças com tags; há políticas de substituição (LRU, FIFO, etc.) e tipos de mapeamento (direto, associativo, set-associativo).\n",
      "- Coerência em multi-core: quando vários núcleos compartilham dados, rola controle de coerência (MESI, invalidação) para não virar um multipista de desinformação.\n",
      "\n",
      "Também vale lembrar:\n",
      "- Modos de escrita: write-back (escreve no cache e só depois na RAM) vs write-through; políticas de alocação de escrita (write allocate) afetam o desempenho.\n",
      "- Misses existem: compulsórios, de capacidade e de conflito; cada um atrasa a performance de um jeito dramático, porém previsível.\n",
      "- Impacto prático: código “cache-friendly” (loops lineares, acessos contínuos) se sai muito melhor do que código que apanha a memória aleatoriamente.\n",
      "\n",
      "Em resumo: a cache é a ponte rápida entre CPU e RAM, tentando adivinhar o que você vai usar a seguir para manter o processador alimentado com dados o mais veloz possível.\n",
      "{'input_tokens': 27, 'output_tokens': 1572, 'total_tokens': 1599, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1152}}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt Few Shot\n",
   "id": "291435286a239e11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T21:34:51.211265Z",
     "start_time": "2025-09-05T21:34:47.084283Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sábado.\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(content='Qual o primeiro dia da semana?'),\n",
    "    AIMessage(content='Domingo'),\n",
    "    HumanMessage(content='Qual o terceiro dia da semana?'),\n",
    "    AIMessage(content='Terça-Feira'),\n",
    "    HumanMessage(content='Qual o última dia da semana?'),\n",
    "]\n",
    "\n",
    "answer = chat.invoke(messages)\n",
    "print(answer.content)\n"
   ],
   "id": "6c60cdd9446d9976"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cacheamento InMemoryCache\n",
    "Toda vez que reiniciar a aplicação o cache se perde"
   ],
   "id": "74ae6d1b9990de38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T15:40:06.475263Z",
     "start_time": "2025-09-06T15:40:00.384184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "load_dotenv()\n",
    "chat = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Você é um assistente irônico'),\n",
    "    HumanMessage(content='Qual é o quinto dia da semana?')\n",
    "]\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "start_time = time.time()\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"--- O script demorou {duration:.2f} segundos para rodar. ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"--- O script demorou {duration:.2f} segundos para rodar. ---\")\n"
   ],
   "id": "4ddab868b9acd85a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quinto dia da semana? Sexta-feira. A menos que você conte começando pelo domingo — aí seria quinta-feira. Na prática moderna (ISO 8601, segunda como primeiro dia), fica sexta-feira.\n",
      "--- O script demorou 6.09 segundos para rodar. ---\n",
      "Quinto dia da semana? Sexta-feira. A menos que você conte começando pelo domingo — aí seria quinta-feira. Na prática moderna (ISO 8601, segunda como primeiro dia), fica sexta-feira.\n",
      "--- O script demorou 0.00 segundos para rodar. ---\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Memória com SQLLiteCache\n",
   "id": "233b3e7f4ebe9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T21:05:36.972045Z",
     "start_time": "2025-09-06T21:05:36.964001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "load_dotenv()\n",
    "chat = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='Você é um assistente irônico'),\n",
    "    HumanMessage(content='Qual é o quinto dia da semana?')\n",
    "]\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path='files/langchain_cache.sqlite'))\n",
    "\n",
    "start_time = time.time()\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"--- O script demorou {duration:.2f} segundos para rodar. ---\")"
   ],
   "id": "fdc01274c3532ede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depende de como você conta a semana.\n",
      "\n",
      "- Se a semana começa no domingo: quinto dia é quinta-feira.\n",
      "- Se a semana começa na segunda: quinto dia é sexta-feira.\n",
      "\n",
      "No Brasil, muitas contagens começam na segunda, então o quinto dia costuma ser sexta-feira. Quer que eu siga um padrão específico para você?\n",
      "--- O script demorou 0.00 segundos para rodar. ---\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
